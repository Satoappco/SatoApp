#!/bin/bash
# Run CI/CD pipeline locally (mimics GitHub Actions)
# Usage: ./scripts/run-ci-locally.sh

set -e  # Exit on error

echo "üöÄ Running CI/CD Pipeline Locally"
echo "=================================="

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Detect docker-compose command (v1 vs v2)
if command -v docker-compose &> /dev/null; then
  DOCKER_COMPOSE="docker-compose"
elif command -v docker &> /dev/null && docker compose version &> /dev/null; then
  DOCKER_COMPOSE="docker compose"
else
  echo -e "${RED}‚ùå Error: docker-compose or docker compose not found${NC}"
  echo "Please install Docker and Docker Compose"
  exit 1
fi

# Step 1: Start PostgreSQL
echo -e "\n${YELLOW}üì¶ Step 1: Starting PostgreSQL service${NC}"
$DOCKER_COMPOSE -f docker-compose.test.yml up -d

# Wait for PostgreSQL to be ready
echo -e "${YELLOW}‚è≥ Waiting for PostgreSQL to be ready...${NC}"
for i in {1..30}; do
  if $DOCKER_COMPOSE -f docker-compose.test.yml exec -T postgres-test pg_isready -h localhost -p 5433 -U postgres > /dev/null 2>&1; then
    echo -e "${GREEN}‚úÖ PostgreSQL is ready!${NC}"
    sleep 2  # Additional wait for full initialization
    break
  fi
  echo "Waiting... ($i/30)"
  sleep 1
done

# Step 2: Install dependencies
echo -e "\n${YELLOW}üì¶ Step 2: Installing dependencies${NC}"
pip install -q -r requirements.txt

# Step 3: Run linting (basic)
echo -e "\n${YELLOW}üîç Step 3: Running linting${NC}"
python -m py_compile app/**/*.py 2>/dev/null || echo -e "${YELLOW}‚ö†Ô∏è  Some files failed to compile (non-critical)${NC}"

# Step 4: Run unit tests
echo -e "\n${YELLOW}üß™ Step 4: Running unit tests${NC}"
export DATABASE_URL="sqlite:///:memory:"
export GEMINI_API_KEY="dummy-key-for-testing"

if pytest tests/unit/ -v --cov=app --cov-report=xml --tb=short; then
  echo -e "${GREEN}‚úÖ Unit tests passed!${NC}"
else
  echo -e "${RED}‚ùå Unit tests failed!${NC}"
  $DOCKER_COMPOSE -f docker-compose.test.yml down
  exit 1
fi

# Step 5: Run integration tests
echo -e "\n${YELLOW}üß™ Step 5: Running integration tests${NC}"
export TEST_DATABASE_URL="postgresql://postgres:postgres@localhost:5433/postgres"

if pytest tests/integration/ -v --tb=short; then
  echo -e "${GREEN}‚úÖ Integration tests passed!${NC}"
else
  echo -e "${RED}‚ùå Integration tests failed!${NC}"
  $DOCKER_COMPOSE -f docker-compose.test.yml down
  exit 1
fi

# Step 6: Generate test report
echo -e "\n${YELLOW}üìä Step 6: Generating test report${NC}"
mkdir -p reports
# Run only unit and e2e tests for HTML report (integration tests already validated in Step 5)
# This avoids test isolation issues and environment variable conflicts
export DATABASE_URL="sqlite:///:memory:"
export GEMINI_API_KEY="dummy-key-for-testing"
pytest tests/unit tests/e2e --html=reports/test-report.html --self-contained-html || true

# Step 7: Show coverage report
echo -e "\n${YELLOW}üìä Coverage Report:${NC}"
if [ -f coverage.xml ]; then
  echo "Coverage report generated: coverage.xml"
  echo "View HTML report: open htmlcov/index.html"
else
  echo "No coverage report found"
fi

# Cleanup
echo -e "\n${YELLOW}üßπ Cleaning up PostgreSQL${NC}"
$DOCKER_COMPOSE -f docker-compose.test.yml down

# Success
echo -e "\n${GREEN}=================================="
echo -e "‚úÖ All CI/CD steps completed successfully!"
echo -e "==================================${NC}\n"

# Show test report location
if [ -f reports/test-report.html ]; then
  echo -e "üìä Test report: ${GREEN}reports/test-report.html${NC}"
  echo -e "   Open with: ${YELLOW}open reports/test-report.html${NC}"
fi

if [ -f htmlcov/index.html ]; then
  echo -e "üìä Coverage report: ${GREEN}htmlcov/index.html${NC}"
  echo -e "   Open with: ${YELLOW}open htmlcov/index.html${NC}"
fi
